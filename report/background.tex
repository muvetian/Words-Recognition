
\section{Background}
\label{sec:background}

We investigated into the use of multi-layer perceptron. This is a
Neural Network regression classifier that includes a hidden layer
where the input is transformed into a more seperable layer. Many
hidden layers can be added to the model and we used two different
transformations to create the hidden data. The first is the identity
which is a no-operation activation. It just returns the same out put
as was inputed or $f(x)=x$. The second transformation we used was
described in the paper tilte,
and transformed the input into a rectified linear unit function.\cite{milgram} This
transformation returns $f(x)=max(0,x)$ and was used in the paper as a
baseline but we had not fully understood their further studys and so
this became one of our better classifiers. \\




