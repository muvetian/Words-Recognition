
\section{Experiments}
\label{sec:expts}
It should be noted that in the original data set if every pixel grey scale value were to be used as a feature to train for the model might result in a huge set of features. Having such set of features may cause a commnon phenomena known as "the curse of dimensionality", which implicates that the increase in the dimensional space resulted from the increase in the number of features might dilute the statisical significance of the final result.\cite{bellman}
That being said, in order to reduce the complexity of the final model in the hope of avoiding overfitting problems, a feature selection process was implemented for the experiments.\cite{hall}
\subsection{Feature Selections}
\label{feature}
According to Hall, feature selection process consists of the following steps:
\begin{itemize}
	\item Starting point
	\item Search orgnization
	\item Evaluation strategy
	\item Stopping criterion

\end{itemize}
As introduced in the "Background" section, after some inspections through the data sets, it was observed that some pixels' grey scale values stayed the same all the time. Those points generally tend to have no significant impacs on the predictions according to the low-variance rule. Thus, those features could be the starting points. For this purpose,the backward elemination method was adpoted to reduce the number of features.\cite{hall}
The evaluation strategy is basically reducing the features that had the lowest chi-squared scores one by one using the chi-squared feature selection method implemented in the scikit-learn library. This process would be repeated until the results showed significant decline in the performance of the models generated by the learning algorithms. For the purpose of determining the optimal set of features, the SVM algorithm was implemented for its short running time.

\subsection{Classifiers}
\label{class}
For this particular classification problem, several models were implemented and tested out. Here
\paragraph{Super Vector Machines}
SVM serves as the baseline model for the experiments due to its simplistic nature. It is also used for finding the optimal set of features.
\paragraph{Multi-layered Perceptron}

